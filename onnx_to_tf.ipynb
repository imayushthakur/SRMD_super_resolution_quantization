{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ee6020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "import os\n",
    "import time\n",
    "import tensorflow_hub as hub\n",
    "os.environ[\"TFHUB_DOWNLOAD_PROGRESS\"] = \"True\"\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import cv2\n",
    "import os.path\n",
    "import logging\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "from scipy.io import loadmat\n",
    "from utils.network_srmd import SRMD as net \n",
    "from utils import utils_deblur\n",
    "from utils import utils_sisr as sr\n",
    "from utils import utils_logger\n",
    "from utils import utils_image as util\n",
    "from utils import utils_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38955b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_srmd(img):\n",
    "    img_name, ext = os.path.splitext(os.path.basename(img))\n",
    "    img_L = util.imread_uint(img, n_channels=3)\n",
    "    img_L = cv2.resize(img_L, (179,179))\n",
    "    img_L = util.uint2single(img_L)\n",
    "    noise_level_model = 0\n",
    "    srmd_pca_path = os.path.join('kernels', 'srmd_pca_matlab.mat')\n",
    "    kernel = utils_deblur.fspecial('gaussian', 15, 0.01)\n",
    "    P = loadmat(srmd_pca_path)['P']\n",
    "    degradation_vector = np.dot(P, np.reshape(kernel, (-1), order=\"F\"))\n",
    "    degradation_vector = np.append(degradation_vector, noise_level_model/255.)\n",
    "    degradation_vector = torch.from_numpy(degradation_vector).view(1, -1, 1, 1).float()\n",
    "    img_L = util.single2tensor4(img_L)\n",
    "    degradation_map = degradation_vector.repeat(1, 1, img_L.size(-2), img_L.size(-1))\n",
    "    img_L = torch.cat((img_L, degradation_map), dim=1)\n",
    "    img_L = img_L.to(\"cpu\")\n",
    "    return img_L\n",
    "\n",
    "def post_process(output, mod_pad_h, mod_pad_w, mod_scale=4, pre_pad=10):\n",
    "    scale=1 # hardcoded for model_scale=4\n",
    "    # remove extra pad\n",
    "    if mod_scale is not None:\n",
    "        _, _, h, w = output.size()\n",
    "        output = output[:, :, 0:h - mod_pad_h * scale, 0:w - mod_pad_w * scale]\n",
    "    # remove prepad\n",
    "    if pre_pad != 0:\n",
    "        _, _, h, w = output.size()\n",
    "        output = output[:, :, 0:h - pre_pad * scale, 0:w - pre_pad * scale]\n",
    "    # unsqueze to remove batch\n",
    "    output = output.squeeze().float().cpu().clamp_(0, 1).numpy()\n",
    "    # convert to channel last\n",
    "    output = np.transpose(output, (1, 2, 0))\n",
    "    output = (output * 255.0).round().astype(np.uint8)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def preprocess(img_path, pre_pad=10, mod_scale=4):\n",
    "    img = cv2.imread(img_path)\n",
    "    h_input, w_input = img.shape[0:2]\n",
    "    # img: numpy\n",
    "    img = img.astype(np.float32)\n",
    "    if np.max(img) > 256:  # 16-bit image\n",
    "        max_range = 65535\n",
    "        print('\\tInput is a 16-bit image')\n",
    "    else:\n",
    "        max_range = 255\n",
    "    img = img / max_range\n",
    "    if len(img.shape) == 2:  # gray image\n",
    "        img_mode = 'L'\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    elif img.shape[2] == 4:  # RGBA image with alpha channel\n",
    "        img_mode = 'RGBA'\n",
    "        alpha = img[:, :, 3]\n",
    "        img = img[:, :, 0:3]\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if alpha_upsampler == 'realesrgan':\n",
    "            alpha = cv2.cvtColor(alpha, cv2.COLOR_GRAY2RGB)\n",
    "    else:\n",
    "        img_mode = 'RGB'\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = torch.from_numpy(np.transpose(img, (2, 0, 1))).float()\n",
    "    img = img.unsqueeze(0).to(\"cuda\")\n",
    "    img = F.pad(img, (0, pre_pad, 0, pre_pad), 'reflect')\n",
    "    \n",
    "    mod_pad_h, mod_pad_w = 0, 0\n",
    "    _, _, h, w = img.size()\n",
    "    if (h % mod_scale != 0):\n",
    "        mod_pad_h = (mod_scale - h % mod_scale)\n",
    "    if (w % mod_scale != 0):\n",
    "        mod_pad_w = (mod_scale - w % mod_scale)\n",
    "    img = F.pad(img, (0, mod_pad_w, 0, mod_pad_h), 'reflect')\n",
    "    \n",
    "    return img, mod_pad_h, mod_pad_w\n",
    "\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "def save_image(image, filename):\n",
    "  \"\"\"\n",
    "    Saves unscaled Tensor Images.\n",
    "    Args:\n",
    "      image: 3D image tensor. [height, width, channels]\n",
    "      filename: Name of the file to save.\n",
    "  \"\"\"\n",
    "  if not isinstance(image, Image.Image):\n",
    "    image = tf.clip_by_value(image, 0, 255)\n",
    "    image = Image.fromarray(tf.cast(image, tf.uint8).numpy())\n",
    "  image.save(\"%s.jpg\" % filename)\n",
    "  print(\"Saved as %s.jpg\" % filename)\n",
    "    \n",
    "%matplotlib inline\n",
    "def plot_image(image, title=\"\"):\n",
    "  \"\"\"\n",
    "    Plots images from image tensors.\n",
    "    Args:\n",
    "      image: 3D image tensor. [height, width, channels].\n",
    "      title: Title to display in the plot.\n",
    "  \"\"\"\n",
    "  image = np.asarray(image)\n",
    "  image = tf.clip_by_value(image, 0, 255)\n",
    "  image = Image.fromarray(tf.cast(image, tf.uint8).numpy())\n",
    "  plt.imshow(image)\n",
    "  plt.axis(\"off\")\n",
    "  plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f839a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_path = \"srmd_x4.onnx\"\n",
    "tf_path = \"tf_model/\"\n",
    "\n",
    "onnx_model = onnx.load(onnx_path)  # load onnx model\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "tf_rep = prepare(onnx_model)\n",
    "tf_rep.export_graph(tf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb76c0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_path = \"tf_model/\"\n",
    "model = tf.saved_model.load(tf_path)\n",
    "print(list(model.signatures.keys()))  # [\"serving_default\"]\n",
    "\n",
    "infer = model.signatures[\"serving_default\"]\n",
    "print(infer.structured_outputs)\n",
    "# infer.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b970f275",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"C:/Users/ayush/Rizzle/52_images_super_resolution_testing/Images/360p_images/people_4.jpg\"\n",
    "preprocessed_image, mod_pad_h, mod_pad_w = preprocess(IMAGE_PATH)\n",
    "srmd_preprocessed_img = preprocess_srmd(IMAGE_PATH)\n",
    "# print(hr_image.shape)\n",
    "hr_np = preprocessed_image.cpu().numpy()\n",
    "print(preprocessed_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55045ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotting Original Resolution image\n",
    "post_process_output = post_process(preprocessed_image, mod_pad_h, mod_pad_w)\n",
    "print(post_process_output.shape)\n",
    "print(tf.squeeze(preprocessed_image.cpu().numpy()).shape)\n",
    "plot_image(post_process_output, title=\"Original Image\")\n",
    "save_image(post_process_output, filename=\"Original Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84d2f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "x = tf.convert_to_tensor(srmd_preprocessed_img.numpy(), dtype=tf.float32, name=\"input0\")\n",
    "fake_image = infer(x)\n",
    "print(\"Time Taken: %f\" % (time.time() - start))\n",
    "fake_image = tf.squeeze(fake_image[\"output0\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568f46a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_image = tf.expand_dims(fake_image, 0)\n",
    "fake_image = torch.from_numpy(fake_image.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d083e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_process_output = post_process(fake_image, mod_pad_h, mod_pad_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2578a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_process_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92915329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Super Resolution Image\n",
    "plot_image(post_process_output, title=\"Super Resolution\")\n",
    "save_image(post_process_output, filename=\"Super Resolution\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
